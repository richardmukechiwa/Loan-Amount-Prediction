{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\Loan-Amount-Prediction'"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from constants and utils\n",
    "from credit_risk.constants import *\n",
    "from credit_risk.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creating a Configuration class\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath   = CONFIG_FILE_PATH,\n",
    "        params_filepath   = PARAMS_FILE_PATH,\n",
    "        schema_filepath   = SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)                       \n",
    "        self.schema = read_yaml(schema_filepath)  \n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_transformation_config(self)->DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir  = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from credit_risk import logger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"C:/Users/RICH-FILES/Desktop/ml/Loan-Amount-Prediction\"\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add EDA to the data \n",
    "def data_cleaning(self, df):\n",
    "    df = pd.read_csv(\"artifacts/data_ingestion/credit_risk.csv\")\n",
    "    #remove categorical data\n",
    "    df.drop(columns = [\"Id\", \"Home\", \"Intent\", \"Status\", \"Default\"], inplace=True)\n",
    "    #drop null values\n",
    "    df.dropna()\n",
    "    \n",
    "    #remove outliers\n",
    "    df = df[(df['Age'] < 25) & (df['Emp_length'] < 10)]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Emp_length</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Percent_income</th>\n",
       "      <th>Cred_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>9900</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>78956</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17823</th>\n",
       "      <td>22</td>\n",
       "      <td>19200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17828</th>\n",
       "      <td>24</td>\n",
       "      <td>48200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17829</th>\n",
       "      <td>23</td>\n",
       "      <td>117696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>6.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17831</th>\n",
       "      <td>24</td>\n",
       "      <td>38000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.89</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17832</th>\n",
       "      <td>22</td>\n",
       "      <td>52000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9750</td>\n",
       "      <td>13.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11939 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Income  Emp_length  Amount   Rate  Percent_income  Cred_length\n",
       "1       21    9600         5.0    1000  11.14            0.10            2\n",
       "3       23   65500         4.0   35000  15.23            0.53            2\n",
       "4       24   54400         8.0   35000  14.27            0.55            4\n",
       "5       21    9900         2.0    2500   7.14            0.25            2\n",
       "7       24   78956         5.0   35000  11.11            0.44            4\n",
       "...    ...     ...         ...     ...    ...             ...          ...\n",
       "17823   22   19200         0.0    3000    NaN            0.16            2\n",
       "17828   24   48200         3.0    5000  10.38            0.10            3\n",
       "17829   23  117696         2.0   15000   6.03            0.13            4\n",
       "17831   24   38000         0.0   12000  11.89            0.32            3\n",
       "17832   22   52000         6.0    9750  13.06            0.19            2\n",
       "\n",
       "[11939 rows x 7 columns]"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning(self,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the missing values\n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing values\n",
    "#df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check descriptive statistics\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check non numeric columns\n",
    "#df.describe(include='object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the homes are rented and the most of the loans are intented for educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the target variable\n",
    "#df['Amount'].hist()\n",
    "#plt.ylabel('Count')\n",
    "#plt.xlabel('Amount')    \n",
    "#plt.title('Loan Amount Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is right-skewed, meaning most loan amounts fall in the lower range (below 10,000), while fewer loans exist at higher amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Amount distribution by Age   \n",
    "#plt.figure(figsize=(12,6))\n",
    "#sns.scatterplot(x='Age', y='Amount', data=df) \n",
    "#plt.xlabel('Age')\n",
    "#plt.ylabel('Amount')            \n",
    "#plt.title('Loan Amount by Age');      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the loan applicants are between the age 23 to 45 years and there are three outliers above 100 years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Amount distribution by Income\n",
    "#plt.figure(figsize=(12,6))\n",
    "#sns.scatterplot(x='Income', y='Amount', data=df)    \n",
    "#plt.xlabel('Income')\n",
    "#plt.ylabel('Amount')\n",
    "#plt.title('Loan Amount by Income');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- most of the income values are concentrated on the left side (closer to zero).\n",
    "\n",
    "- A few extreme outliers have very high incomes (above $1M)\n",
    "\n",
    "- Loan amounts do not seem to increase proportionally with income, even those with high income are taking loans of varying amounts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #loan purpose count\n",
    "#plt.figure(figsize=(12,6))\n",
    "#df[\"Intent\"].value_counts().plot(kind='bar')\n",
    "#plt.ylabel('Count')\n",
    "#plt.xlabel('Intent')\n",
    "#plt.title('Loan Intent Distribution');   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the loan applications are going towards education followed by medical, venture, personal, debtconsolidation and the least number of applications are for homeimprovements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check multicollinearity and correlation\n",
    "#plt.figure(figsize=(12,6))  \n",
    "#corr = df.select_dtypes(include=['int64', 'float64']).drop('Amount', axis=1).corr()    \n",
    "#sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "#plt.title('Correlation Matrix');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a strong correlatedness between Age and Cred_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column Id and Cred_length , Status, Default   \n",
    "#columns_to_drop = [\"Id\", \"Cred_length\", \"Status\", \"Default\"]\n",
    "#df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "#pd.options.mode.copy_on_write=True\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "#cat_features    = df[[\"Home\", \"Intent\"]]\n",
    "#num_features   = df[[\"Age\",\t\"Income\", \"Emp_length\", \"Amount\",\t\"Rate\", \t\"Percent_income\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform categorical data and stardardize the data\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.pipeline import Pipeline   \n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the column StandardScaler\n",
    "#numerical_processor = Pipeline(\n",
    "    #steps =[(\"standard scaling\",  StandardScaler()\n",
    "    #)]  \n",
    "#)\n",
    "        \n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the column OneHotEncoder\n",
    "#categorical_processor = Pipeline(\n",
    "    #steps =[(\"one hot encoding\", OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    #)]  \n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the column transformer\n",
    "#preprocessor = ColumnTransformer(\n",
    "    #transformers=[\n",
    "        #(\"numerical\", numerical_processor, num_features.columns),\n",
    "        #(\"categorical\", categorical_processor, cat_features.columns)\n",
    "    #]\n",
    "#)   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the preprocessor\n",
    "#preprocessor.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data\n",
    "#transformed_data=preprocessor.transform(df)  \n",
    "\n",
    "#data=pd.DataFrame(transformed_data)\n",
    "#data.columns = num_features.columns.tolist() + preprocessor.named_transformers_[\"categorical\"][\"one hot encoding\"].get_feature_names_out().tolist()\n",
    "#data.to_csv(\"artifacts/data_ingestion/credit_risk.csv\", index=False)     \n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "        project_path = \"C:/Users/RICH-FILES/Desktop/ml/Loan-Amount-Prediction\"\n",
    "\n",
    "        os.chdir(project_path)\n",
    "        \n",
    "                    \n",
    "    def train_test_splitting(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        \n",
    "        #split the data into train and test\n",
    "        train, test = train_test_split(data, test_size=0.2, random_state=42)  \n",
    "        \n",
    "        train.to_csv(os.path.join(self.config.root_dir, 'train.csv'), index=False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, 'test.csv'), index=False)        #save the train and test data to the root directory     \n",
    "        \n",
    "        logger.info(\"Data split into train and test data\")  \n",
    "        logger.info(f\"Train data shape: {train.shape}\")         \n",
    "        logger.info(f\"Test data shape: {test.shape}\")  \n",
    "        \n",
    "        print(train.shape)\n",
    "        print(test.shape)                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-06 23:38:25,433: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-06 23:38:25,437: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-06 23:38:25,442: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-03-06 23:38:25,444: INFO: common: created directory at: artifacts]\n",
      "[2025-03-06 23:38:25,445: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-03-06 23:38:25,683: INFO: 550626937: Data split into train and test data]\n",
      "[2025-03-06 23:38:25,683: INFO: 550626937: Train data shape: (26064, 12)]\n",
      "[2025-03-06 23:38:25,686: INFO: 550626937: Test data shape: (6517, 12)]\n",
      "(26064, 12)\n",
      "(6517, 12)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config() \n",
    "    data_transformation = DataTransformation(config = data_transformation_config)\n",
    "    data_transformation.train_test_splitting()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
